{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:25:29.767523Z",
     "iopub.status.busy": "2021-06-04T04:25:29.767116Z",
     "iopub.status.idle": "2021-06-04T04:25:29.776253Z",
     "shell.execute_reply": "2021-06-04T04:25:29.775045Z",
     "shell.execute_reply.started": "2021-06-04T04:25:29.767471Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:25:33.622454Z",
     "iopub.status.busy": "2021-06-04T04:25:33.622142Z",
     "iopub.status.idle": "2021-06-04T04:26:09.603365Z",
     "shell.execute_reply": "2021-06-04T04:26:09.602448Z",
     "shell.execute_reply.started": "2021-06-04T04:25:33.622423Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "!conda install -y gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:26:16.254583Z",
     "iopub.status.busy": "2021-06-04T04:26:16.254237Z",
     "iopub.status.idle": "2021-06-04T04:26:21.155847Z",
     "shell.execute_reply": "2021-06-04T04:26:21.154915Z",
     "shell.execute_reply.started": "2021-06-04T04:26:16.254524Z"
    }
   },
   "outputs": [],
   "source": [
    "!gdown --id 1XVEYb0TN2SbBYOqf8SzazfYZlpH9CxyE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:26:25.189949Z",
     "iopub.status.busy": "2021-06-04T04:26:25.189623Z",
     "iopub.status.idle": "2021-06-04T04:26:29.17465Z",
     "shell.execute_reply": "2021-06-04T04:26:29.173739Z",
     "shell.execute_reply.started": "2021-06-04T04:26:25.189915Z"
    }
   },
   "outputs": [],
   "source": [
    "!unzip model.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:26:29.783482Z",
     "iopub.status.busy": "2021-06-04T04:26:29.783202Z",
     "iopub.status.idle": "2021-06-04T04:26:30.486271Z",
     "shell.execute_reply": "2021-06-04T04:26:30.485313Z",
     "shell.execute_reply.started": "2021-06-04T04:26:29.783453Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls model/ft_ResNet50/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:26:32.199112Z",
     "iopub.status.busy": "2021-06-04T04:26:32.198784Z",
     "iopub.status.idle": "2021-06-04T04:26:32.282678Z",
     "shell.execute_reply": "2021-06-04T04:26:32.281805Z",
     "shell.execute_reply.started": "2021-06-04T04:26:32.19908Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "reid = torch.load('./model/ft_ResNet50/net_last.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model = ./model/ft_net_dense/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:26:33.830083Z",
     "iopub.status.busy": "2021-06-04T04:26:33.829761Z",
     "iopub.status.idle": "2021-06-04T04:26:33.881137Z",
     "shell.execute_reply": "2021-06-04T04:26:33.880201Z",
     "shell.execute_reply.started": "2021-06-04T04:26:33.830052Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torchvision import models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "######################################################################\n",
    "##\n",
    "## DIFFERENT MODELS THAT WE WANTED TO TRY\n",
    "## \n",
    "######################################################################\n",
    "\n",
    "def weights_init_kaiming(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # print(classname)\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in') # For old pytorch, you may use kaiming_normal.\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_out')\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "    elif classname.find('BatchNorm1d') != -1:\n",
    "        init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "def weights_init_classifier(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        init.normal_(m.weight.data, std=0.001)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "# Defines the new fc layer and classification layer\n",
    "# |--Linear--|--bn--|--relu--|--Linear--|\n",
    "class ClassBlock(nn.Module):\n",
    "    def __init__(self, input_dim, class_num, droprate, relu=False, bnorm=True, num_bottleneck=512, linear=True, return_f = False):\n",
    "        super(ClassBlock, self).__init__()\n",
    "        self.return_f = return_f\n",
    "        add_block = []\n",
    "        if linear:\n",
    "            add_block += [nn.Linear(input_dim, num_bottleneck)]\n",
    "        else:\n",
    "            num_bottleneck = input_dim\n",
    "        if bnorm:\n",
    "            add_block += [nn.BatchNorm1d(num_bottleneck)]\n",
    "        if relu:\n",
    "            add_block += [nn.LeakyReLU(0.1)]\n",
    "        if droprate>0:\n",
    "            add_block += [nn.Dropout(p=droprate)]\n",
    "        add_block = nn.Sequential(*add_block)\n",
    "        add_block.apply(weights_init_kaiming)\n",
    "\n",
    "        classifier = []\n",
    "        classifier += [nn.Linear(num_bottleneck, class_num)]\n",
    "        classifier = nn.Sequential(*classifier)\n",
    "        classifier.apply(weights_init_classifier)\n",
    "\n",
    "        self.add_block = add_block\n",
    "        self.classifier = classifier\n",
    "    def forward(self, x):\n",
    "        x = self.add_block(x)\n",
    "        if self.return_f:\n",
    "            f = x\n",
    "            x = self.classifier(x)\n",
    "            return x,f\n",
    "        else:\n",
    "            x = self.classifier(x)\n",
    "            return x\n",
    "\n",
    "# Define the ResNet50-based Model\n",
    "class ft_net(nn.Module):\n",
    "\n",
    "    def __init__(self, class_num, droprate=0.5, stride=2):\n",
    "        super(ft_net, self).__init__()\n",
    "        model_ft = models.resnet50(pretrained=True)\n",
    "        # avg pooling to global pooling\n",
    "        if stride == 1:\n",
    "            self.model.layer4[0].downsample[0].stride = (1,1)\n",
    "            self.model.layer4[0].conv2.stride = (1,1)\n",
    "        model_ft.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.model = model_ft\n",
    "        self.classifier = ClassBlock(2048, class_num, droprate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "        x = self.model.layer4(x)\n",
    "        x = self.model.avgpool(x)\n",
    "        x = x.view(x.size(0), x.size(1))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Define the DenseNet121-based Model\n",
    "class ft_net_dense(nn.Module):\n",
    "\n",
    "    def __init__(self, class_num, droprate=0.5):\n",
    "        super().__init__()\n",
    "        model_ft = models.densenet121(pretrained=True)\n",
    "        model_ft.features.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        model_ft.fc = nn.Sequential()\n",
    "        self.model = model_ft\n",
    "        # For DenseNet, the feature dim is 1024 \n",
    "        self.classifier = ClassBlock(1024, class_num, droprate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.features(x)\n",
    "        x = x.view(x.size(0), x.size(1))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "# Define the ResNet50-based Model (Middle-Concat)\n",
    "# In the spirit of \"The Devil is in the Middle: Exploiting Mid-level Representations for Cross-Domain Instance Matching.\" Yu, Qian, et al. arXiv:1711.08106 (2017).\n",
    "class ft_net_middle(nn.Module):\n",
    "\n",
    "    def __init__(self, class_num, droprate=0.5):\n",
    "        super(ft_net_middle, self).__init__()\n",
    "        model_ft = models.resnet50(pretrained=True)\n",
    "        # avg pooling to global pooling\n",
    "        model_ft.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.model = model_ft\n",
    "        self.classifier = ClassBlock(2048+1024, class_num, droprate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "        # x0  n*1024*1*1\n",
    "        x0 = self.model.avgpool(x)\n",
    "        x = self.model.layer4(x)\n",
    "        # x1  n*2048*1*1\n",
    "        x1 = self.model.avgpool(x)\n",
    "        x = torch.cat((x0,x1),1)\n",
    "        x = x.view(x.size(0), x.size(1))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Part Model proposed in Yifan Sun etal. (2018)\n",
    "class PCB(nn.Module):\n",
    "    def __init__(self, class_num ):\n",
    "        super(PCB, self).__init__()\n",
    "\n",
    "        self.part = 6 # We cut the pool5 to 6 parts\n",
    "        model_ft = models.resnet50(pretrained=True)\n",
    "        self.model = model_ft\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((self.part,1))\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        # remove the final downsample\n",
    "        self.model.layer4[0].downsample[0].stride = (1,1)\n",
    "        self.model.layer4[0].conv2.stride = (1,1)\n",
    "        # define 6 classifiers\n",
    "        for i in range(self.part):\n",
    "            name = 'classifier'+str(i)\n",
    "            setattr(self, name, ClassBlock(2048, class_num, droprate=0.5, relu=False, bnorm=True, num_bottleneck=256))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "        \n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "        x = self.model.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.dropout(x)\n",
    "        part = {}\n",
    "        predict = {}\n",
    "        # get six part feature batchsize*2048*6\n",
    "        for i in range(self.part):\n",
    "            part[i] = torch.squeeze(x[:,:,i])\n",
    "            name = 'classifier'+str(i)\n",
    "            c = getattr(self,name)\n",
    "            predict[i] = c(part[i])\n",
    "\n",
    "        # sum prediction\n",
    "        #y = predict[0]\n",
    "        #for i in range(self.part-1):\n",
    "        #    y += predict[i+1]\n",
    "        y = []\n",
    "        for i in range(self.part):\n",
    "            y.append(predict[i])\n",
    "        return y\n",
    "\n",
    "class PCB_test(nn.Module):\n",
    "    def __init__(self,model):\n",
    "        super(PCB_test,self).__init__()\n",
    "        self.part = 6\n",
    "        self.model = model.model\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((self.part,1))\n",
    "        # remove the final downsample\n",
    "        self.model.layer4[0].downsample[0].stride = (1,1)\n",
    "        self.model.layer4[0].conv2.stride = (1,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "        x = self.model.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        y = x.view(x.size(0),x.size(1),x.size(2))\n",
    "        return y\n",
    "'''\n",
    "# debug model structure\n",
    "# Run this code with:\n",
    "python model.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:26:35.716331Z",
     "iopub.status.busy": "2021-06-04T04:26:35.716012Z",
     "iopub.status.idle": "2021-06-04T04:26:35.721286Z",
     "shell.execute_reply": "2021-06-04T04:26:35.720259Z",
     "shell.execute_reply.started": "2021-06-04T04:26:35.7163Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:26:37.533905Z",
     "iopub.status.busy": "2021-06-04T04:26:37.533588Z",
     "iopub.status.idle": "2021-06-04T04:26:39.247323Z",
     "shell.execute_reply": "2021-06-04T04:26:39.246521Z",
     "shell.execute_reply.started": "2021-06-04T04:26:37.533879Z"
    }
   },
   "outputs": [],
   "source": [
    "## SETTLED WITH RESNET 50 with 751 output classes\n",
    "net = ft_net(751)\n",
    "pretrained_weights = torch.load('./model/ft_ResNet50/net_last.pth')\n",
    "net.load_state_dict(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:26:59.883763Z",
     "iopub.status.busy": "2021-06-04T04:26:59.883378Z",
     "iopub.status.idle": "2021-06-04T04:27:00.578168Z",
     "shell.execute_reply": "2021-06-04T04:27:00.57721Z",
     "shell.execute_reply.started": "2021-06-04T04:26:59.883729Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "### IMPORTING THE BOUNDING BOXES FROM OUR YOLO DATASET\n",
    "with open('../input/bboxes/yolo_bboxes.pickle', 'rb') as handle:\n",
    "    bboxes = pickle.load(handle)\n",
    "    \n",
    "# bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:27:05.962899Z",
     "iopub.status.busy": "2021-06-04T04:27:05.962566Z",
     "iopub.status.idle": "2021-06-04T04:27:06.280506Z",
     "shell.execute_reply": "2021-06-04T04:27:06.275811Z",
     "shell.execute_reply.started": "2021-06-04T04:27:05.962868Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# READING IN A DICT ALL THE dirnames and the output files as joined paths\n",
    "directories = ['campus','lab']\n",
    "output_dir = './reduced_frames3'\n",
    "\n",
    "dir_files = {}\n",
    "\n",
    "for directory in directories:\n",
    "    parent_path = '../input/multi-camera-person-tracking-reduced-frames/reduced_frames/' + directory + \"/\"\n",
    "    dirs = os.listdir(parent_path)\n",
    "    needed = 'asdasd'\n",
    "    for item in dirs:\n",
    "#         print(os.path.join(parent_path,item))\n",
    "        if(os.path.isdir(os.path.join(parent_path,item))):\n",
    "            needed = item\n",
    "#     print(needed)\n",
    "    \n",
    "    for dirname, _, filenames in os.walk('../input/multi-camera-person-tracking-reduced-frames/reduced_frames/' + directory + \"/\" + needed + \"/\"):\n",
    "        files = []\n",
    "        filenames = map(lambda x: x.split(\".\")[0],filenames)\n",
    "        for filename in sorted(filenames,key=int):\n",
    "            files.append(os.path.join(dirname, filename + \".jpg\"))\n",
    "#             print(os.path.join(dirname, filename + \".jpg\"))\n",
    "        dir_files[directory] = files\n",
    "        \n",
    "# out = yolo(args['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:45:43.18066Z",
     "iopub.status.busy": "2021-06-03T22:45:43.180292Z",
     "iopub.status.idle": "2021-06-03T22:45:43.186338Z",
     "shell.execute_reply": "2021-06-03T22:45:43.185281Z",
     "shell.execute_reply.started": "2021-06-03T22:45:43.180621Z"
    }
   },
   "outputs": [],
   "source": [
    "dir_files.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:27:43.030807Z",
     "iopub.status.busy": "2021-06-04T04:27:43.030421Z",
     "iopub.status.idle": "2021-06-04T04:28:35.355236Z",
     "shell.execute_reply": "2021-06-04T04:28:35.354257Z",
     "shell.execute_reply.started": "2021-06-04T04:27:43.030772Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "## CROPPING THE IMAGES\n",
    "\n",
    "cropped_imgs = {}\n",
    "flag = 0\n",
    "features = []\n",
    "for key in dir_files:\n",
    "    imgs = {}\n",
    "    print(key)\n",
    "    for image_path in dir_files[key]:\n",
    "        img = np.array(Image.open(image_path).convert('RGB'))\n",
    "        img_num = image_path.split('/')[-1].split('.')[0]\n",
    "        imgs[img_num] = []\n",
    "        for bbox in bboxes[key][img_num]:\n",
    "#             print(img_num,bbox)\n",
    "            class_id,x,y,w,h = bbox\n",
    "            if(class_id == 0):\n",
    "#                 print(img.shape)\n",
    "                person_img = img[max(0,y):min(y + h,img.shape[0]),max(0,x):min(x + w,img.shape[1])]\n",
    "                plt.imshow(person_img)\n",
    "                person_img = Image.fromarray(np.uint8(person_img)).convert('RGB')\n",
    "                imgs[img_num].append(person_img)\n",
    "#                 print(imgs)\n",
    "    cropped_imgs[key] = imgs\n",
    "#                 flag = 1\n",
    "#                 break\n",
    "#         if(flag):\n",
    "#             break\n",
    "#     if(flag):\n",
    "#         break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:28:42.775558Z",
     "iopub.status.busy": "2021-06-04T04:28:42.775225Z",
     "iopub.status.idle": "2021-06-04T04:28:47.794323Z",
     "shell.execute_reply": "2021-06-04T04:28:47.793323Z",
     "shell.execute_reply.started": "2021-06-04T04:28:42.775511Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# STORING THE CROPPED IMAGES\n",
    "!rm -rf cropped_ppl\n",
    "!mkdir cropped_ppl\n",
    "# import pickle\n",
    "for key in cropped_imgs:\n",
    "    for scene in cropped_imgs[key]:\n",
    "        if(cropped_imgs[key][scene]):\n",
    "#             print(\"./cropped_ppl/\" + key + \"_\" + scene)\n",
    "            cnt = 0\n",
    "            for people in cropped_imgs[key][scene]:\n",
    "                people.save(\"./cropped_ppl/\" + key + \"_\" + scene + \"_\" + str(cnt) + \".jpg\")\n",
    "                cnt += 1\n",
    "#         print(cropped_imgs[key][scene])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:29:21.106456Z",
     "iopub.status.busy": "2021-06-04T04:29:21.106124Z",
     "iopub.status.idle": "2021-06-04T04:29:37.001571Z",
     "shell.execute_reply": "2021-06-04T04:29:37.000603Z",
     "shell.execute_reply.started": "2021-06-04T04:29:21.106422Z"
    }
   },
   "outputs": [],
   "source": [
    "# CREATING A DATASET OUT OF THE CROPPED IMAGE INTO DIFFERENT SCENES\n",
    "\n",
    "dataset = {}\n",
    "for key in cropped_imgs:\n",
    "    dataset[key] = []\n",
    "    for scene in cropped_imgs[key]:\n",
    "        ppl_scene = []\n",
    "        if(cropped_imgs[key][scene]):\n",
    "            for people in cropped_imgs[key][scene]:\n",
    "                dataset[key].append(people)\n",
    "\n",
    "total_dataset = []\n",
    "total_dataset.extend(list(dataset.values())[0])\n",
    "total_dataset.extend(list(dataset.values())[1])\n",
    "\n",
    "len(total_dataset)\n",
    "for i in range(len(total_dataset)):\n",
    "    total_dataset[i] = preprocess(total_dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:29:38.804914Z",
     "iopub.status.busy": "2021-06-04T04:29:38.8046Z",
     "iopub.status.idle": "2021-06-04T04:29:38.843133Z",
     "shell.execute_reply": "2021-06-04T04:29:38.842172Z",
     "shell.execute_reply.started": "2021-06-04T04:29:38.804884Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:29:43.414351Z",
     "iopub.status.busy": "2021-06-04T04:29:43.414015Z",
     "iopub.status.idle": "2021-06-04T04:29:45.443807Z",
     "shell.execute_reply": "2021-06-04T04:29:45.442928Z",
     "shell.execute_reply.started": "2021-06-04T04:29:43.414321Z"
    }
   },
   "outputs": [],
   "source": [
    "total_dataset = torch.stack(total_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:29:47.133999Z",
     "iopub.status.busy": "2021-06-04T04:29:47.13361Z",
     "iopub.status.idle": "2021-06-04T04:29:47.141209Z",
     "shell.execute_reply": "2021-06-04T04:29:47.140264Z",
     "shell.execute_reply.started": "2021-06-04T04:29:47.133953Z"
    }
   },
   "outputs": [],
   "source": [
    "total_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:29:49.345711Z",
     "iopub.status.busy": "2021-06-04T04:29:49.345366Z",
     "iopub.status.idle": "2021-06-04T04:29:49.352294Z",
     "shell.execute_reply": "2021-06-04T04:29:49.351427Z",
     "shell.execute_reply.started": "2021-06-04T04:29:49.345679Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "bs = 32\n",
    "data = DataLoader(total_dataset, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:29:51.660509Z",
     "iopub.status.busy": "2021-06-04T04:29:51.660186Z",
     "iopub.status.idle": "2021-06-04T04:29:51.670331Z",
     "shell.execute_reply": "2021-06-04T04:29:51.669501Z",
     "shell.execute_reply.started": "2021-06-04T04:29:51.660477Z"
    }
   },
   "outputs": [],
   "source": [
    "iterator = iter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:29:52.949175Z",
     "iopub.status.busy": "2021-06-04T04:29:52.948852Z",
     "iopub.status.idle": "2021-06-04T04:29:52.952501Z",
     "shell.execute_reply": "2021-06-04T04:29:52.951695Z",
     "shell.execute_reply.started": "2021-06-04T04:29:52.949145Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:29:54.67009Z",
     "iopub.status.busy": "2021-06-04T04:29:54.669764Z",
     "iopub.status.idle": "2021-06-04T04:29:56.264424Z",
     "shell.execute_reply": "2021-06-04T04:29:56.263361Z",
     "shell.execute_reply.started": "2021-06-04T04:29:54.670059Z"
    }
   },
   "outputs": [],
   "source": [
    "!rm -rf extracted_features\n",
    "!mkdir extracted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:29:57.665192Z",
     "iopub.status.busy": "2021-06-04T04:29:57.664858Z",
     "iopub.status.idle": "2021-06-04T04:29:58.465802Z",
     "shell.execute_reply": "2021-06-04T04:29:58.46474Z",
     "shell.execute_reply.started": "2021-06-04T04:29:57.665159Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls extracted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:30:00.006299Z",
     "iopub.status.busy": "2021-06-04T04:30:00.005962Z",
     "iopub.status.idle": "2021-06-04T04:30:00.011202Z",
     "shell.execute_reply": "2021-06-04T04:30:00.010395Z",
     "shell.execute_reply.started": "2021-06-04T04:30:00.006264Z"
    }
   },
   "outputs": [],
   "source": [
    "dlen = len(total_dataset)\n",
    "niters = dlen // bs\n",
    "print(dlen, niters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T23:07:15.631065Z",
     "iopub.status.busy": "2021-06-03T23:07:15.630751Z",
     "iopub.status.idle": "2021-06-03T23:07:15.637928Z",
     "shell.execute_reply": "2021-06-03T23:07:15.636949Z",
     "shell.execute_reply.started": "2021-06-03T23:07:15.631036Z"
    }
   },
   "outputs": [],
   "source": [
    "iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:30:12.168684Z",
     "iopub.status.busy": "2021-06-04T04:30:12.168343Z",
     "iopub.status.idle": "2021-06-04T04:30:28.816373Z",
     "shell.execute_reply": "2021-06-04T04:30:28.81559Z",
     "shell.execute_reply.started": "2021-06-04T04:30:12.168647Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## EXTRACTING RESNET FEATURES IN OUR DATASET\n",
    "features = []\n",
    "net = net.to(device)\n",
    "# dlen = len(total_dataset)\n",
    "# niters = dlen // bs\n",
    "for i in range(niters):\n",
    "    x = next(iterator).to(device)\n",
    "    out = net(x)\n",
    "    print(\"iter \", i, \" \", out.shape)\n",
    "    torch.save(out, 'extracted_features/out' + str(i) + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:30:32.305608Z",
     "iopub.status.busy": "2021-06-04T04:30:32.305251Z",
     "iopub.status.idle": "2021-06-04T04:30:32.435842Z",
     "shell.execute_reply": "2021-06-04T04:30:32.435031Z",
     "shell.execute_reply.started": "2021-06-04T04:30:32.305573Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## COMBINED FEATURE VECTOR\n",
    "\n",
    "path = './extracted_features/out'\n",
    "features = torch.Tensor([])\n",
    "for i in range(niters):\n",
    "    fpath = path + str(i) + '.pth'\n",
    "    if i == 0:\n",
    "        features = torch.load(fpath)\n",
    "    else:\n",
    "        features = torch.vstack((features, torch.load(fpath)))\n",
    "    print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:31:24.345809Z",
     "iopub.status.busy": "2021-06-04T04:31:24.345468Z",
     "iopub.status.idle": "2021-06-04T04:31:24.360634Z",
     "shell.execute_reply": "2021-06-04T04:31:24.359634Z",
     "shell.execute_reply.started": "2021-06-04T04:31:24.345777Z"
    }
   },
   "outputs": [],
   "source": [
    "## FINDING AN INVERSE RELATION BETWEEN AN IMAGE ID IN THE SCENE TO THE FRAME IN SCENE\n",
    "\n",
    "img_set = []\n",
    "total_imgid_to_frame = {}\n",
    "\n",
    "for scene in cropped_imgs:\n",
    "    if(len(total_imgid_to_frame.keys()) > 0):\n",
    "        start = len(total_imgid_to_frame.keys())\n",
    "    imgid_to_frame = {}\n",
    "    people_counter = 0\n",
    "    for frame in cropped_imgs[scene]:\n",
    "        ppl_scene = []\n",
    "        if(cropped_imgs[scene][frame]):\n",
    "            for people in cropped_imgs[scene][frame]:\n",
    "                imgid_to_frame[people_counter] = frame\n",
    "                img_set.append(people)\n",
    "                people_counter += 1\n",
    "    total_imgid_to_frame[scene] = imgid_to_frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:32:46.595937Z",
     "iopub.status.busy": "2021-06-04T04:32:46.595581Z",
     "iopub.status.idle": "2021-06-04T04:32:46.600384Z",
     "shell.execute_reply": "2021-06-04T04:32:46.599441Z",
     "shell.execute_reply.started": "2021-06-04T04:32:46.595906Z"
    }
   },
   "outputs": [],
   "source": [
    "## A dict which stores how many extra non-needed frames needs to be added to this key to get the image in feature matrix\n",
    "dataset_to_totalDataset = {}\n",
    "start = 0\n",
    "for key in dataset:\n",
    "    dataset_to_totalDataset[key] = start\n",
    "    start = len(dataset[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:32:47.756215Z",
     "iopub.status.busy": "2021-06-04T04:32:47.755896Z",
     "iopub.status.idle": "2021-06-04T04:32:47.762143Z",
     "shell.execute_reply": "2021-06-04T04:32:47.76122Z",
     "shell.execute_reply.started": "2021-06-04T04:32:47.756186Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_to_totalDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:32:48.880445Z",
     "iopub.status.busy": "2021-06-04T04:32:48.88014Z",
     "iopub.status.idle": "2021-06-04T04:32:48.932874Z",
     "shell.execute_reply": "2021-06-04T04:32:48.931938Z",
     "shell.execute_reply.started": "2021-06-04T04:32:48.880416Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scene Image - Scene Frame Dict connection\n",
    "total_imgid_to_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:32:53.619424Z",
     "iopub.status.busy": "2021-06-04T04:32:53.619105Z",
     "iopub.status.idle": "2021-06-04T04:32:53.625021Z",
     "shell.execute_reply": "2021-06-04T04:32:53.622895Z",
     "shell.execute_reply.started": "2021-06-04T04:32:53.619394Z"
    }
   },
   "outputs": [],
   "source": [
    "cos = torch.nn.CosineSimilarity(dim=1, eps=1e-08)\n",
    "# person_same_threshold = 0.15\n",
    "person_same_threshold = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:37:16.675306Z",
     "iopub.status.busy": "2021-06-04T04:37:16.674984Z",
     "iopub.status.idle": "2021-06-04T04:37:16.679069Z",
     "shell.execute_reply": "2021-06-04T04:37:16.678011Z",
     "shell.execute_reply.started": "2021-06-04T04:37:16.675274Z"
    }
   },
   "outputs": [],
   "source": [
    "# net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:33:09.671068Z",
     "iopub.status.busy": "2021-06-04T04:33:09.670755Z",
     "iopub.status.idle": "2021-06-04T04:33:09.759912Z",
     "shell.execute_reply": "2021-06-04T04:33:09.759126Z",
     "shell.execute_reply.started": "2021-06-04T04:33:09.671037Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## SETTING UP THE QUERY IMAGE\n",
    "start = time.time()\n",
    "query_image = Image.open('../input/query-imgs/query_img_pres_2.png').convert('RGB')\n",
    "query_dataset = torch.stack([preprocess(query_image),preprocess(query_image)])\n",
    "query_dataset = query_dataset.to(device) \n",
    "net.eval()\n",
    "out_features = net(query_dataset)\n",
    "\n",
    "query_feature = out_features[0]\n",
    "\n",
    "out_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T01:16:51.285492Z",
     "iopub.status.busy": "2021-06-04T01:16:51.285152Z",
     "iopub.status.idle": "2021-06-04T01:16:51.293789Z",
     "shell.execute_reply": "2021-06-04T01:16:51.292622Z",
     "shell.execute_reply.started": "2021-06-04T01:16:51.285457Z"
    }
   },
   "outputs": [],
   "source": [
    "# features[dataset_to_totalDataset[scene] + 287]\n",
    "dataset[scene][287]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:33:50.294871Z",
     "iopub.status.busy": "2021-06-04T04:33:50.294482Z",
     "iopub.status.idle": "2021-06-04T04:33:50.882665Z",
     "shell.execute_reply": "2021-06-04T04:33:50.881721Z",
     "shell.execute_reply.started": "2021-06-04T04:33:50.294838Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## EXTRACTING THE CLOSEST PERSON PICTURES FROM THE SIMILARITY AND THRESHOLD FUNCTION\n",
    "\n",
    "query_img_index = 287\n",
    "same_guy = []\n",
    "import time\n",
    "\n",
    "scene = 'lab'\n",
    "query = query_feature\n",
    "query\n",
    "\n",
    "for i in range(len(dataset[scene])):\n",
    "    img_feature = features[dataset_to_totalDataset[scene] + i]\n",
    "#     print(img_feature,query)\n",
    "#     similarity = cos(img_feature.reshape(-1, features[dataset_to_totalDataset[scene] + i].shape[0]), query.reshape(-1, query.shape[0])).item()\n",
    "    similarity = torch.dot(img_feature, query).item()\n",
    "#     print (i, similarity)\n",
    "    if similarity > person_same_threshold:\n",
    "#         print (i, similarity)\n",
    "        same_guy.append(i)\n",
    "end = time.time()\n",
    "print (\"Total Time from Kaggle sent:\",end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T01:15:07.005362Z",
     "iopub.status.busy": "2021-06-04T01:15:07.005105Z",
     "iopub.status.idle": "2021-06-04T01:15:07.028342Z",
     "shell.execute_reply": "2021-06-04T01:15:07.027604Z",
     "shell.execute_reply.started": "2021-06-04T01:15:07.005337Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "same_guy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:34:24.616345Z",
     "iopub.status.busy": "2021-06-04T04:34:24.616026Z",
     "iopub.status.idle": "2021-06-04T04:34:24.630559Z",
     "shell.execute_reply": "2021-06-04T04:34:24.629669Z",
     "shell.execute_reply.started": "2021-06-04T04:34:24.616312Z"
    }
   },
   "outputs": [],
   "source": [
    "## DISPLAYING QUERY IMAGE\n",
    "Image.open('../input/query-imgs/query_img_pres_2.png').convert('RGB')\n",
    "# plt.imshow(np.array(dataset[scene][query_img_index]))\n",
    "# plt.savefig('query_img.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img_set[287] accuracy is 96.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:34:43.808315Z",
     "iopub.status.busy": "2021-06-04T04:34:43.807991Z",
     "iopub.status.idle": "2021-06-04T04:34:53.527141Z",
     "shell.execute_reply": "2021-06-04T04:34:53.526286Z",
     "shell.execute_reply.started": "2021-06-04T04:34:43.808285Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "## DISPLAYING THE CLOSEST 160 frames in our SCENE\n",
    "w = 8\n",
    "h = 20\n",
    "\n",
    "loadimg = lambda index: dataset[scene][same_guy[index]].resize((250, 250))\n",
    "\n",
    "_, axes_list = plt.subplots(h, w, figsize=(20, 40)) # define a grid of (w, h)\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "for axes in axes_list:\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "        cnt += 1\n",
    "        ax.imshow(loadimg(cnt)) # load and show\n",
    "plt.savefig('pink t shirt, query_index = 287, dot.png')\n",
    "#         ax.set_title(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T04:36:43.582907Z",
     "iopub.status.busy": "2021-06-04T04:36:43.582548Z",
     "iopub.status.idle": "2021-06-04T04:36:43.800521Z",
     "shell.execute_reply": "2021-06-04T04:36:43.767549Z",
     "shell.execute_reply.started": "2021-06-04T04:36:43.582869Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in same_guy:\n",
    "    print(\"Frame ID:\",total_imgid_to_frame[scene][i],end = \">>|<<\")\n",
    "    \n",
    "\n",
    "# dataset['lab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
